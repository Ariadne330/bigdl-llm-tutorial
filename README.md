# BigDL-LLM Tutorial

[_BigDL-LLM_](https://github.com/intel-analytics/BigDL/tree/main/python/llm) is a low-bit LLM library on Intel XPU (Xeon/Core/Flex/Arc/PVC). This repository contains tutorials to help you understand what is _BigDL-LLM_ and how to use _BigDL-LLM_ to build LLM applications.

The tutorials are organized as follows:
- Chapter 1 **`Introduction`** introduces what is _BigDL-LLM_ and what you can do with it. 
- Chapter 2 **`Environment Setup`** provides a set of best practices for setting-up your environment.
- Chapter 3 **`Application Development: Basics`** introduces the basic usage of _BigDL-LLM_ and how to build a very simple Chat application.
- Chapter 4 **`Chinese Support`** shows the usage of some LLMs which suppports Chinese input/output, e.g. ChatGLM2, Baichuan  
- Chapter 5 **`Application Development: Intermediate`** introduces intermediate-level knowledge for application development using _BigDL-LLM_, e.g. How to build a more sophisticated Chatbot, Speech recoginition, etc. 
- Chapter 6 **`GPU Acceleration`** introduces how to use Intel GPU to accelerate LLMs using _BigDL-LLM_.
- Chapter 7 **`Finetune`** introduces how to do Finetune using _BigDL-LLM_.
- Chapter 8 **`Application Development: Advanced`** introduces advanced-level knowledge for application development using _BigDL-LLM_, e.g. langchain usage. 

[^1]: Performance varies by use, configuration and other factors. `bigdl-llm` may not optimize to the same degree for non-Intel products. Learn more at www.Intel.com/PerformanceIndex.
