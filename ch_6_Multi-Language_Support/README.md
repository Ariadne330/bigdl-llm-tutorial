# Chapter 6 Multi-Language Support

This chapter we will explore the ability of large languange models in handling multiple languages. Multi-language support is of great importance for a large language model due to its far-reaching implications and real-world applications. This capability has opened new horizons in communication, research and cross-cultural understanding.

Therefore, in the large language model, multi-language support is an indispensable part. Many models we are familiar with have support for multiple languages, such as: [ChatGPT](https://openai.com/blog/chatgpt), [ChatGLM](https://chatglm.cn/blog), [Baichuan](https://huggingface.co/baichuan-inc/Baichuan-13B-Chat), [Llama](https://huggingface.co/docs/transformers/main/model_doc/llama), etc.

Large language model achieve this ability by training on a diverse corpus of text from different languages. Through this training process, the model learns not only the grammar and vocabulary of each language but also the details and context that make language unique.

We provide two notebook examples showing the usage of two popular multi-language models, using Chinese for illustration.

+ [ChatGLM2-6B](chatglm2-tutorial.ipynb)
+ [Baichuan-13B](baichuan-tutorial.ipynb)